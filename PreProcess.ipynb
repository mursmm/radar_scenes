{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "273fd7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1efe6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "training_data_file = 'C:/Users/myrsi/Documents/msc_thesis/training_data.csv'\n",
    "validation_data_file = 'C:/Users/myrsi/Documents/msc_thesis/validation_data.csv'\n",
    "\n",
    "df_training_data = pd.read_csv(training_data_file)\n",
    "df_validation_data = pd.read_csv(validation_data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e993bbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Angle        RCS  Range_Sc  Doppler_Vel  Label_ID\n",
      "0 -0.124031 -28.300673  2.566963     0.009330        11\n",
      "1  0.849328 -26.863953  2.096815    -8.023678        11\n",
      "2  1.106456 -26.564907  3.338323    -9.334642        11\n",
      "3  1.156905   0.101503  8.882484    -7.361293        11\n",
      "4  1.090472  -3.724234  9.479269    -7.834501        11\n",
      "      Angle        RCS   Range_Sc  Doppler_Vel  Label_ID\n",
      "0 -0.949410  -8.967562  15.204274     0.013444        11\n",
      "1 -0.927236  -8.756395   8.291416    -0.204751        11\n",
      "2 -0.318540 -23.922726  10.212634    -0.002552        11\n",
      "3  0.490461 -20.036438  10.412143     0.002362        11\n",
      "4  0.385698 -11.150873  16.565825    -0.001025        11\n"
     ]
    }
   ],
   "source": [
    "# Access the data in the DataFrame\n",
    "# For example, print the first 5 rows of the DataFrame\n",
    "print(df_training_data.head())\n",
    "print(df_validation_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc4cc8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NaN values in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "has_nan = df_training_data.isna().any().any()\n",
    "#has_nan = df_validation_data.isna().any().any()\n",
    "\n",
    "# Print the result\n",
    "if has_nan:\n",
    "    print(\"There are NaN values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"There are no NaN values in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "793db4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'Doppler_Vel' column contains zero values.\n"
     ]
    }
   ],
   "source": [
    "# Check if 'Doppler_Vel' column has zero values\n",
    "#has_zeros = any(df_training_data['Doppler_Vel'] == 0)\n",
    "has_zeros = any(df_validation_data['Doppler_Vel'] == 0)\n",
    "\n",
    "if has_zeros:\n",
    "    print(\"The 'Doppler_Vel' column contains zero values.\")\n",
    "else:\n",
    "    print(\"The 'Doppler_Vel' column does not contain zero values.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32c2f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with non-zero values in 'Doppler_Vel' column\n",
    "\n",
    "df_training_data_static = df_training_data[df_training_data['Doppler_Vel'] == 0]\n",
    "df_validation_data_static = df_validation_data[df_validation_data['Doppler_Vel'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0ba5608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Angle        RCS   Range_Sc  Doppler_Vel  Label_ID\n",
      "8466    0.073331 -15.673953  36.329308          0.0        11\n",
      "92228   0.087288   7.818957  37.510777          0.0        11\n",
      "322656  1.112901   8.035492  10.215149          0.0        11\n",
      "335977  0.101549 -12.426669  11.838837          0.0        11\n",
      "394798  0.661913 -25.315552   5.563264          0.0        11\n",
      "         Angle        RCS   Range_Sc  Doppler_Vel  Label_ID\n",
      "450   0.554729 -22.479916  10.081914          0.0        11\n",
      "482  -0.291218  21.703321  51.351340          0.0        11\n",
      "679   0.102620  26.898014  68.092430          0.0        11\n",
      "1180 -0.314791  15.404928  48.002570          0.0        11\n",
      "1189 -0.244994  19.542840  57.628696          0.0        11\n"
     ]
    }
   ],
   "source": [
    "print(df_training_data_static.head())\n",
    "print(df_validation_data_static.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2fb6a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'Doppler_Vel' column does not contain any non-zero values.\n"
     ]
    }
   ],
   "source": [
    "# Check if 'Doppler_Vel' column has any non-zero values\n",
    "has_non_zeros = any(df_training_data_static['Doppler_Vel'] != 0)\n",
    "#has_non_zeros = any(df_validation_data_static['Doppler_Vel'] != 0)\n",
    "\n",
    "if has_non_zeros:\n",
    "    print(\"The 'Doppler_Vel' column contains non-zero values.\")\n",
    "else:\n",
    "    print(\"The 'Doppler_Vel' column does not contain any non-zero values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e0f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the features and labels. Remove the extra column(Doppler_vel) because i don't need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "473b9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_training_data_static[['Angle','RCS','Range_Sc']]\n",
    "y = df_training_data_static['Label_ID']\n",
    "X_val = df_validation_data_static[['Angle','RCS','Range_Sc',]]\n",
    "y_val = df_validation_data_static['Label_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa5010c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Angle        RCS   Range_Sc\n",
      "8466    0.073331 -15.673953  36.329308\n",
      "92228   0.087288   7.818957  37.510777\n",
      "322656  1.112901   8.035492  10.215149\n",
      "335977  0.101549 -12.426669  11.838837\n",
      "394798  0.661913 -25.315552   5.563264\n",
      "8466      11\n",
      "92228     11\n",
      "322656    11\n",
      "335977    11\n",
      "394798    11\n",
      "Name: Label_ID, dtype: int64\n",
      "         Angle        RCS   Range_Sc\n",
      "450   0.554729 -22.479916  10.081914\n",
      "482  -0.291218  21.703321  51.351340\n",
      "679   0.102620  26.898014  68.092430\n",
      "1180 -0.314791  15.404928  48.002570\n",
      "1189 -0.244994  19.542840  57.628696\n",
      "450     11\n",
      "482     11\n",
      "679     11\n",
      "1180    11\n",
      "1189    11\n",
      "Name: Label_ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())\n",
    "print(X_val.head())\n",
    "print(y_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9ce6a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a371f9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame,\n",
       " pandas.core.series.Series,\n",
       " pandas.core.frame.DataFrame,\n",
       " pandas.core.series.Series)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X), type(y), type(X_val), type(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61ff6756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn data into tensors\n",
    "# Otherwise this causes issues with computations later on\n",
    "X = torch.Tensor(df_training_data_static[['Angle', 'RCS', 'Range_Sc']].values)\n",
    "y = torch.Tensor(df_training_data_static['Label_ID'].values)\n",
    "\n",
    "X_val = torch.Tensor(df_validation_data_static[['Angle', 'RCS', 'Range_Sc']].values)\n",
    "y_val = torch.Tensor(df_validation_data_static['Label_ID'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e74b9a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32, torch.float32, torch.float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first five samples\n",
    "X[:5], y[:5], X_val[:5], y_val[:5]\n",
    "X.dtype, y.dtype, X_val.dtype, y_val.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ca08a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143743, 143743, 38508, 38508)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b85c2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "val_proportion = df_validation_data_static.shape[0] / df_training_data_static.shape[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=val_proportion,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "34c08abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105235, 38508, 38508, 105235, 38508, 38508)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(X_val), len(y_train), len(y_test), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4fe375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 5\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32db76de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Make device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40ef225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat gpt updated version\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the CSV file\n",
    "training_data_file = 'C:/Users/myrsi/Documents/msc_thesis/training_data.csv'\n",
    "validation_data_file = 'C:/Users/myrsi/Documents/msc_thesis/validation_data.csv'\n",
    "df_training_data = pd.read_csv(training_data_file)\n",
    "df_validation_data = pd.read_csv(validation_data_file)\n",
    "\n",
    "# Remove rows with non-zero values in 'Doppler_Vel' column\n",
    "df_training_data_static = df_training_data[df_training_data['Doppler_Vel'] == 0]\n",
    "df_validation_data_static = df_validation_data[df_validation_data['Doppler_Vel'] == 0]\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = df_training_data_static[['Angle', 'RCS', 'Range_Sc']].values\n",
    "y_train = df_training_data_static['Label_ID'].values\n",
    "X_val = df_validation_data_static[['Angle', 'RCS', 'Range_Sc']].values\n",
    "y_val = df_validation_data_static['Label_ID'].values\n",
    "\n",
    "# Split the training data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=val_proportion, random_state=42)\n",
    "\n",
    "# Convert data to tensors\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "X_val = torch.Tensor(X_val)\n",
    "y_val = torch.Tensor(y_val)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 5\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a46cd8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(6, 6), stride=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(9, 9), stride=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (upsample1): Upsample(size=2, mode=nearest)\n",
      "  (deconv1): ConvTranspose2d(256, 128, kernel_size=(9, 9), stride=(1, 1))\n",
      "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(6, 6), stride=(1, 1))\n",
      "  (bn6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (upsample2): Upsample(size=2, mode=nearest)\n",
      "  (deconv3): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv4): ConvTranspose2d(32, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the model architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=6)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=9)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.upsample1 = nn.Upsample(size=2)\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=9)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=6)\n",
    "        self.bn6 = nn.BatchNorm2d(64)\n",
    "        self.upsample2 = nn.Upsample(size=2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=5)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.deconv4 = nn.ConvTranspose2d(in_channels=32, out_channels=6, kernel_size=3)\n",
    "\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x))) \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)    \n",
    "        x = F.relu(self.bn3(self.conv3(x))) \n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)     \n",
    "\n",
    "        x = self.upsample1(x)\n",
    "        x = F.relu(self.bn5(self.deconv1(x))) \n",
    "        x = F.relu(self.bn6(self.deconv2(x)))\n",
    "        x = self.upsample2(x)\n",
    "        x = F.relu(self.bn7(self.deconv3(x))) \n",
    "        x = self.deconv4(x)\n",
    "\n",
    "\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.softmax(self.fc2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "##for fc linear im not sure. not in article.   \n",
    "\n",
    "#instantiate a neural network model\n",
    "\n",
    "model = Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "05efb1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x00000217AEE62320>, <torch.utils.data.dataloader.DataLoader object at 0x00000215A05C3AC0>, <torch.utils.data.dataloader.DataLoader object at 0x00000217AEE62BC0>)\n",
      "Length of train dataloader: 21047 batches of 5\n",
      "Length of test dataloader: 7702 batches of 5\n",
      "Length of val dataloader: 7702 batches of 5\n"
     ]
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_train\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader, val_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of val dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9c5b9505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.Size([5]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e516de17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(6, 6), stride=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(9, 9), stride=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (upsample1): Upsample(size=2, mode=nearest)\n",
      "  (deconv1): ConvTranspose2d(256, 128, kernel_size=(9, 9), stride=(1, 1))\n",
      "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(6, 6), stride=(1, 1))\n",
      "  (bn6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (upsample2): Upsample(size=2, mode=nearest)\n",
      "  (deconv3): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv4): ConvTranspose2d(32, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=4096, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=6, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=6)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=9)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.upsample1 = nn.Upsample(size=2)\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=9)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=6)\n",
    "        self.bn6 = nn.BatchNorm2d(64)\n",
    "        self.upsample2 = nn.Upsample(size=2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=5)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.deconv4 = nn.ConvTranspose2d(in_channels=32, out_channels=6, kernel_size=3)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)  # Add a fully connected layer\n",
    "        self.fc2 = nn.Linear(256, 6)  # Add another fully connected layer\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Add a dropout layer\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.upsample1(x)\n",
    "        x = F.relu(self.bn5(self.deconv1(x)))\n",
    "        x = F.relu(self.bn6(self.deconv2(x)))\n",
    "        x = self.upsample2(x)\n",
    "        x = F.relu(self.bn7(self.deconv3(x)))\n",
    "        x = self.deconv4(x)\n",
    "\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.softmax(self.fc2(x))\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "model = Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3b57add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3df7e5a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X_train)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Optimizer zero grad\u001b[39;00m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3013\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "# Put data to target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        X_train, y_train = data\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = model(X_train).squeeze()\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        \n",
    "        # Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Loss backward \n",
    "        loss.backward\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a476d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f32bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e13f672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079fad72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c121f7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
